{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-27T04:06:15.326870Z",
     "start_time": "2025-08-27T04:06:15.238302Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T04:06:18.037654Z",
     "start_time": "2025-08-27T04:06:15.332738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "minio_endpoint = os.getenv(\"STORAGE_URI\", \"http://222.255.214.74:9000\")\n",
    "minio_access_key = os.getenv(\"MINIO_ACCESS_KEY\", \"admin\")\n",
    "minio_secret_key = os.getenv(\"MINIO_SECRET_KEY\", \"password\")\n",
    "MINIO_S3_FILE_PATH = \"s3a://csv-data-files/HR_Data_MNC_Data.csv\"\n",
    "\n",
    "spark = (SparkSession.builder.appName(\"PostgreSQL ingestion from file\")\n",
    "         .config(\"spark.jars.packages\",\n",
    "                 \",\".join([\"org.postgresql:postgresql:42.7.4\",\n",
    "                           \"org.apache.hadoop:hadoop-aws:3.3.4\",\n",
    "                           \"com.amazonaws:aws-java-sdk-bundle:1.12.262\"\n",
    "                           ]))\n",
    "         # Cap driver and executor heaps:\n",
    "         .config(\"spark.driver.memory\", \"2g\")\n",
    "         .config(\"spark.executor.memory\", \"2g\")\n",
    "         .getOrCreate())\n",
    "jdbc_url = os.getenv(\"JDBC_URL\", \"jdbc:postgresql://localhost:5435/mydb\")\n",
    "file_path = \"../csv_files/HR_Data_MNC_Data.csv\"\n",
    "\n",
    "target_table = \"public.hr_data\"\n",
    "db_user = \"myuser\"\n",
    "db_password = \"mypassword\"\n",
    "\n",
    "use_minio = True\n",
    "\n",
    "if use_minio:\n",
    "    # Configure S3A to talk to MinIO\n",
    "    hconf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "    hconf.set(\"fs.s3a.endpoint\", minio_endpoint)  # MinIO endpoint\n",
    "    hconf.set(\"fs.s3a.access.key\", minio_access_key)\n",
    "    hconf.set(\"fs.s3a.secret.key\", minio_secret_key)\n",
    "    hconf.set(\"fs.s3a.path.style.access\", \"true\")  # required for MinIO\n",
    "    hconf.set(\"fs.s3a.connection.ssl.enabled\", \"false\")  # set true if your MinIO uses HTTPS\n",
    "    hconf.set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "\n"
   ],
   "id": "16a8251f0b460d7f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/27 11:06:15 WARN Utils: Your hostname, MacBook-Air-cua-Ngoc-2.local resolves to a loopback address: 127.0.0.1; using 192.168.1.5 instead (on interface en0)\n",
      "25/08/27 11:06:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/truongngocson/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/truongngocson/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ea10509d-541a-4172-ac98-75153e767b97;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/truongngocson/Documents/Projects/apache-iceberg/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.postgresql#postgresql;42.7.4 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 150ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.42.0 from local-m2-cache in [default]\n",
      "\torg.postgresql#postgresql;42.7.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ea10509d-541a-4172-ac98-75153e767b97\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/6ms)\n",
      "25/08/27 11:06:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read data into dataframe",
   "id": "8fe2933a3b8b8443"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T04:06:51.305007Z",
     "start_time": "2025-08-27T04:06:18.088242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if use_minio:\n",
    "    print(\"Start reading file from MinIO\")\n",
    "    df = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")  # consider providing an explicit schema for production\n",
    "        .csv(MINIO_S3_FILE_PATH)\n",
    "    )\n",
    "    df.show()\n",
    "else:\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "    df.show()"
   ],
   "id": "2abef0d0b78cf06a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start reading file from MinIO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/27 11:06:18 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---------------+----------+--------------------+----------+--------------------+------------------+----------------+--------+---------+----------+\n",
      "|Unnamed: 0|Employee_ID|      Full_Name|Department|           Job_Title| Hire_Date|            Location|Performance_Rating|Experience_Years|  Status|Work_Mode|Salary_INR|\n",
      "+----------+-----------+---------------+----------+--------------------+----------+--------------------+------------------+----------------+--------+---------+----------+\n",
      "|         0| EMP0000001|  Joshua Nguyen|        IT|   Software Engineer|2011-08-10|  Isaacland, Denmark|                 5|              14|Resigned|  On-site|   1585363|\n",
      "|         1| EMP0000002| Julie Williams| Marketing|      SEO Specialist|2018-03-02|Anthonyside, Cost...|                 2|               7|  Active|  On-site|    847686|\n",
      "|         2| EMP0000003|Alyssa Martinez|        HR|          HR Manager|2023-03-20|Port Christinapor...|                 1|               2|  Active|  On-site|   1430084|\n",
      "|         3| EMP0000004|Nicholas Valdez|        IT|   Software Engineer|2023-10-12|Port Shelbycheste...|                 1|               1|  Active|  On-site|    990689|\n",
      "|         4| EMP0000005| Joel Hendricks|Operations|Logistics Coordin...|2024-12-09|Lake Kimberly, Pa...|                 5|               0|  Active|  On-site|    535082|\n",
      "|         5| EMP0000006|  Jason Gardner|Operations|Logistics Coordin...|2021-02-23|Zimmermanstad, Bu...|                 5|               4|  Active|  On-site|    641393|\n",
      "|         6| EMP0000007|   Julie Wright|   Finance|     Finance Manager|2016-04-04|Karenfort, South ...|                 2|               9|  Active|  On-site|   1383891|\n",
      "|         7| EMP0000008|   Scott Wilson|     Sales|     Account Manager|2020-04-04|Moniqueview, Brit...|                 2|               5|  Active|   Remote|    423091|\n",
      "|         8| EMP0000009| Cathy Thompson|   Finance|   Financial Analyst|2018-05-29|South Catherine, ...|                 4|               7|Resigned|   Remote|   1138452|\n",
      "|         9| EMP0000010|    Maria Yu MD|        IT|   Software Engineer|2015-10-08|    Brownport, Yemen|                 4|               9|  Active|   Remote|   1543102|\n",
      "|        10| EMP0000011|  Jordan Haynes|     Sales|     Sales Executive|2018-10-27|Lake Katherinelan...|                 1|               6|  Active|  On-site|    617992|\n",
      "|        11| EMP0000012|     Kevin Lowe|     Sales|     Account Manager|2024-07-02|    East Kent, Qatar|                 3|               1|Resigned|  On-site|   1111759|\n",
      "|        12| EMP0000013|    Glen Miller|Operations|Operations Executive|2011-05-03|Coreybury, Libyan...|                 3|              14|  Active|  On-site|    512635|\n",
      "|        13| EMP0000014| Roberto Nguyen|        HR|        HR Executive|2020-08-24|South Sandraview,...|                 4|               4|  Active|  On-site|    572479|\n",
      "|        14| EMP0000015|Megan Hernandez|     Sales|     Account Manager|2016-01-14|New Royberg, Thai...|                 5|               9|  Active|   Remote|   1158764|\n",
      "|        15| EMP0000016| Julie Marshall| Marketing|      SEO Specialist|2021-07-19|Port Phillip, Poland|                 5|               4|  Active|  On-site|    602022|\n",
      "|        16| EMP0000017|  Robert Martin|Operations|Logistics Coordin...|2025-05-13|Laurahaven, Afgha...|                 3|               0|Resigned|  On-site|    859025|\n",
      "|        17| EMP0000018| Mark Rodriguez|     Sales|      Sales Director|2016-09-17| Maryshire, Botswana|                 3|               8|  Active|   Remote|    508563|\n",
      "|        18| EMP0000019|Samuel Ferguson|        IT|     DevOps Engineer|2025-04-05|Matthewsville, Ghana|                 2|               0|  Active|  On-site|    631273|\n",
      "|        19| EMP0000020| Donald Hoffman| Marketing|  Content Strategist|2022-04-01|South James, New ...|                 3|               3|Resigned|  On-site|    965154|\n",
      "+----------+-----------+---------------+----------+--------------------+----------+--------------------+------------------+----------------+--------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Start ingesting data",
   "id": "623a551bf943bc4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T04:08:13.613164Z",
     "start_time": "2025-08-27T04:06:51.439422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Starting ingestion into PostgreSQL with connection: {jdbc_url}')\n",
    "\n",
    "write = (df.write.format(\"jdbc\")\n",
    "         .option(\"url\", jdbc_url)\n",
    "         .option(\"dbtable\", target_table)\n",
    "         .option(\"user\", db_user)\n",
    "         .option(\"password\", db_password)\n",
    "         .option(\"driver\", \"org.postgresql.Driver\")\n",
    "         #.option(\"batchsize\", 10000)\n",
    "         .option(\"truncate\", \"true\")\n",
    "         .option(\"createTableOptions\", \"WITH (OIDS=FALSE)\")\n",
    "         # Create table options (used if the table doesn't exist and Spark creates it):\n",
    "         )\n",
    "\n",
    "write.mode(\"append\").save()\n",
    "print(\"Done!\")"
   ],
   "id": "e7102bde0461dd83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ingestion into PostgreSQL with connection: jdbc:postgresql://222.255.214.74:5435/mydb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Shutdown session",
   "id": "86ed27551fbd324"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T04:08:13.697232Z",
     "start_time": "2025-08-27T04:08:13.654665Z"
    }
   },
   "cell_type": "code",
   "source": "spark.stop()",
   "id": "9fdaa077ff1c2f43",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
