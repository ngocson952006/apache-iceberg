{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ingestion data to Iceberg using Pyspark",
   "id": "1cd389d03faebe8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T07:16:47.624072Z",
     "start_time": "2025-08-25T07:16:46.211901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "# Function to install Maven (Linux/macOS only; Windows users must install manually)\n",
    "def install_maven():\n",
    "    try:\n",
    "        # Check if Maven is already installed\n",
    "        subprocess.run([\"mvn\", \"-version\"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print(\"Maven is already installed.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Maven not found. Installing Maven...\")\n",
    "        subprocess.run([\"sudo\", \"apt\", \"update\"], check=True)\n",
    "        subprocess.run([\"sudo\", \"apt\", \"install\", \"-y\", \"maven\"], check=True)  # For Linux (apt)\n",
    "        print(\"Maven installed successfully.\")\n",
    "\n",
    "\n",
    "# Function to download a specific JAR using Maven\n",
    "def download_jar(group_id, artifact_id, version):\n",
    "    try:\n",
    "        print(f\"Downloading JAR: {group_id}:{artifact_id}:{version}\")\n",
    "        subprocess.run([\n",
    "            \"mvn\", \"dependency:copy\",\n",
    "            f\"-Dartifact={group_id}:{artifact_id}:{version}\"\n",
    "        ], check=True)\n",
    "        print(f\"JAR downloaded successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to download JAR: {e}\")\n",
    "\n",
    "\n",
    "# Ensure Maven is installed\n",
    "install_maven()\n",
    "# Download required JAR(s)\n",
    "download_jar(\"org.slf4j\", \"slf4j-api\", \"1.7.30\")\n"
   ],
   "id": "a18a847b5c6738dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maven is already installed.\n",
      "Downloading JAR: org.slf4j:slf4j-api:1.7.30\n",
      "[INFO] Scanning for projects...\n",
      "[INFO] \n",
      "[INFO] ------------------< org.apache.maven:standalone-pom >-------------------\n",
      "[INFO] Building Maven Stub Project (No POM) 1\n",
      "[INFO] --------------------------------[ pom ]---------------------------------\n",
      "[INFO] \n",
      "[INFO] --- dependency:3.7.0:copy (default-cli) @ standalone-pom ---\n",
      "[INFO] Configured Artifact: org.slf4j:slf4j-api:1.7.30:jar\n",
      "[INFO] org.slf4j:slf4j-api:1.7.30:jar already exists in /Users/truongngocson/Documents/Projects/apache-iceberg/notebooks/${project.basedir}/target/dependency\n",
      "[INFO] ------------------------------------------------------------------------\n",
      "[INFO] BUILD SUCCESS\n",
      "[INFO] ------------------------------------------------------------------------\n",
      "[INFO] Total time:  0.428 s\n",
      "[INFO] Finished at: 2025-08-25T14:16:47+07:00\n",
      "[INFO] ------------------------------------------------------------------------\n",
      "JAR downloaded successfully\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-25T07:16:51.747692Z",
     "start_time": "2025-08-25T07:16:47.627932Z"
    }
   },
   "source": [
    "import pyspark\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "## DEFINE VARIABLES\n",
    "catalog_uri = os.getenv('CATALOG_URI', \"http://localhost:19120/api/v1\")\n",
    "warehouse = \"s3://warehouse/\"\n",
    "storage_uri = os.getenv('STORAGE_URI', \"http://127.0.0.1:9000\")\n",
    "# Define the JDBC connection properties\n",
    "jdbc_url = os.getenv('JDBC_URL', \"jdbc:postgresql://localhost:5435/mydb\")\n",
    "properties = {\n",
    "    \"user\": \"myuser\",\n",
    "    \"password\": \"mypassword\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "local_jars = ','.join([\n",
    "    'slf4j-api-1.7.30.jar'\n",
    "])\n",
    "\n",
    "## CONFIGURE SPARK SESSION\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "    .setAppName('Iceberg Ingestion')\n",
    "    .set('spark.jars.packages',\n",
    "         'org.postgresql:postgresql:42.7.3,'\n",
    "         'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0,'\n",
    "         'org.projectnessie.nessie-integrations:nessie-spark-extensions-3.5_2.12:0.77.1,'\n",
    "         'software.amazon.awssdk:bundle:2.24.8,'\n",
    "         'software.amazon.awssdk:url-connection-client:2.24.8')\n",
    "    .set('spark.sql.extensions',\n",
    "         'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions,'\n",
    "         'org.projectnessie.spark.extensions.NessieSparkSessionExtensions')\n",
    "    .set('spark.sql.catalog.nessie', 'org.apache.iceberg.spark.SparkCatalog')\n",
    "    .set('spark.sql.catalog.nessie.uri', catalog_uri)\n",
    "    .set('spark.sql.catalog.nessie.ref', 'main')\n",
    "    .set('spark.sql.catalog.nessie.authentication.type', 'NONE')\n",
    "    .set('spark.sql.catalog.nessie.catalog-impl', 'org.apache.iceberg.nessie.NessieCatalog')\n",
    "    .set('spark.sql.catalog.nessie.s3.endpoint', storage_uri)\n",
    "    .set('spark.sql.catalog.nessie.warehouse', warehouse)\n",
    "    .set('spark.sql.catalog.nessie.io-impl', 'org.apache.iceberg.aws.s3.S3FileIO')\n",
    "\n",
    ")\n",
    "\n",
    "## START SPARK SESSION\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/25 14:16:48 WARN Utils: Your hostname, MacBook-Air-cua-Ngoc-2.local resolves to a loopback address: 127.0.0.1; using 192.168.1.5 instead (on interface en0)\n",
      "25/08/25 14:16:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/truongngocson/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/truongngocson/.ivy2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.5_2.12 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12 added as a dependency\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c0c733b7-eb17-4e03-885c-b9e9fbc33731;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.7.3 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in local-m2-cache\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.77.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.24.8 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/truongngocson/Documents/Projects/apache-iceberg/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound software.amazon.awssdk#url-connection-client;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#utils;2.24.8 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in local-m2-cache\n",
      "\tfound software.amazon.awssdk#annotations;2.24.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in local-m2-cache\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.24.8 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.24.8 in central\n",
      ":: resolution report :: resolve 195ms :: artifacts dl 9ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.5_2.12;1.5.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.42.0 from local-m2-cache in [default]\n",
      "\torg.postgresql#postgresql;42.7.3 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.5_2.12;0.77.1 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from local-m2-cache in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from local-m2-cache in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.24.8 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.24.8 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   12  |   0   |   0   |   0   ||   12  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c0c733b7-eb17-4e03-885c-b9e9fbc33731\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 12 already retrieved (0kB/4ms)\n",
      "25/08/25 14:16:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Start the ingestion",
   "id": "4d6e448c40654e2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T07:17:21.031103Z",
     "start_time": "2025-08-25T07:17:20.488514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Spark Running\")\n",
    "\n",
    "# Read the sales_data table from Postgres into a Spark DataFrame\n",
    "sales_df = spark.read.jdbc(url=jdbc_url, table=\"fashion_sales\", properties=properties)\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "sales_df.show()\n",
    "\n",
    "#Create a namespace\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS nessie.sales;\")\n",
    "\n",
    "# Write the DataFrame to an Iceberg table in the Nessie catalog\n",
    "sales_df.writeTo(\"nessie.sales.fashion_sales\").createOrReplace()\n",
    "\n",
    "# Verify that the data was written to Iceberg by reading the table\n",
    "spark.read.table(\"nessie.sales.fashion_sales\").show()\n",
    "\n",
    "print(\"Ingested data successfully into Iceberg\")"
   ],
   "id": "49c3aa69395cdf9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Running\n",
      "+---+----------------+-----------+------------+----------+--------------+------------------+--------------+\n",
      "| id|    product_name|   category|sales_amount|sales_date|store_location|customer_age_group| campaign_name|\n",
      "+---+----------------+-----------+------------+----------+--------------+------------------+--------------+\n",
      "|  1|  Slim Fit Jeans|      Denim|       89.99|2024-03-01|      New York|             18-24| Spring Launch|\n",
      "|  2|  Leather Jacket|  Outerwear|      249.99|2024-03-01|   Los Angeles|             25-34| Spring Launch|\n",
      "|  3| Graphic T-Shirt|       Tops|       39.99|2024-03-02|       Chicago|             18-24| March Madness|\n",
      "|  4|    Summer Dress|    Dresses|      129.99|2024-03-03|      New York|             35-44| March Madness|\n",
      "|  5| Casual Sneakers|   Footwear|       99.99|2024-03-03|   Los Angeles|             25-34| Spring Launch|\n",
      "|  6|      Silk Scarf|Accessories|      303.30|2025-04-23|       Phoenix|             55-64| Spring Launch|\n",
      "|  7|  Leather Jacket|Accessories|       76.52|2024-06-29|   Los Angeles|               65+| Spring Launch|\n",
      "|  8|Designer Handbag|   Footwear|      308.23|2024-08-04|     San Diego|             35-44|Back to School|\n",
      "|  9|      Silk Scarf|       Tops|       37.18|2025-12-01|       Chicago|             55-64|Back to School|\n",
      "| 10|      Silk Scarf|Accessories|       87.97|2024-03-05|        Dallas|             18-24| March Madness|\n",
      "+---+----------------+-----------+------------+----------+--------------+------------------+--------------+\n",
      "\n",
      "+---+----------------+-----------+------------+----------+--------------+------------------+--------------+\n",
      "| id|    product_name|   category|sales_amount|sales_date|store_location|customer_age_group| campaign_name|\n",
      "+---+----------------+-----------+------------+----------+--------------+------------------+--------------+\n",
      "|  1|  Slim Fit Jeans|      Denim|       89.99|2024-03-01|      New York|             18-24| Spring Launch|\n",
      "|  2|  Leather Jacket|  Outerwear|      249.99|2024-03-01|   Los Angeles|             25-34| Spring Launch|\n",
      "|  3| Graphic T-Shirt|       Tops|       39.99|2024-03-02|       Chicago|             18-24| March Madness|\n",
      "|  4|    Summer Dress|    Dresses|      129.99|2024-03-03|      New York|             35-44| March Madness|\n",
      "|  5| Casual Sneakers|   Footwear|       99.99|2024-03-03|   Los Angeles|             25-34| Spring Launch|\n",
      "|  6|      Silk Scarf|Accessories|      303.30|2025-04-23|       Phoenix|             55-64| Spring Launch|\n",
      "|  7|  Leather Jacket|Accessories|       76.52|2024-06-29|   Los Angeles|               65+| Spring Launch|\n",
      "|  8|Designer Handbag|   Footwear|      308.23|2024-08-04|     San Diego|             35-44|Back to School|\n",
      "|  9|      Silk Scarf|       Tops|       37.18|2025-12-01|       Chicago|             55-64|Back to School|\n",
      "| 10|      Silk Scarf|Accessories|       87.97|2024-03-05|        Dallas|             18-24| March Madness|\n",
      "+---+----------------+-----------+------------+----------+--------------+------------------+--------------+\n",
      "\n",
      "Ingested data successfully into Iceberg\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
